# Проект: Реализация Линейной Регрессии с Нуля

![Python](https://img.shields.io/badge/python-3.9-blue.svg)
![Scikit-learn](https://img.shields.io/badge/scikit--learn-0.23.1-green)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange)

Учебный проект [Школы 21](https://21-school.ru/), посвященный глубокому изучению и самостоятельной реализации линейных моделей для решения задачи регрессии. В рамках проекта были реализованы с нуля ключевые алгоритмы, методы регуляризации и нормализации данных, а также проведен их сравнительный анализ с эталонными реализациями из библиотеки `Scikit-learn`.

## Описание проекта

Этот проект охватывает фундаментальные концепции машинного обучения на примере задачи регрессии. Основное внимание уделяется не только использованию готовых библиотек, но и пониманию внутреннего устройства алгоритмов для построения предсказательных моделей.

Были рассмотрены и реализованы следующие концепции:
*   **Линейная регрессия** и ее математическое обоснование.
*   **Градиентный спуск** как основной метод оптимизации.
*   Проблемы **переобучения (overfitting)** и **недообучения (underfitting)**.
*   Методы борьбы с переобучением: **L1 (Lasso)** и **L2 (Ridge)** регуляризация.
*   **Инженерия признаков (feature engineering)** для улучшения качества модели.
*   **Нормализация данных** и ее влияние на сходимость и точность моделей.
*   Ключевые **метрики качества** для задач регрессии (MAE, RMSE, R²).

## Ключевые возможности

*   **Собственная реализация с нуля:**
    *   Класс `LinearRegression` с использованием стохастического градиентного спуска (SGD).
    *   Регуляризованные модели: `Ridge` (L2), `Lasso` (L1) и `ElasticNet`.
    *   Функции для нормализации признаков: `MinMaxScaler` и `StandardScaler`.
*   **Сравнительный анализ:**
    *   Сравнение производительности собственных реализаций с эталонными моделями из `Scikit-learn`.
    *   Анализ влияния нормализации данных на итоговые метрики.
    *   Исследование работы регуляризации на примере полиномиальных признаков для борьбы с переобучением.
*   **Теоретическая база:**
    *   В Jupyter Notebook содержатся ответы на теоретические вопросы, объясняющие математические основы алгоритмов.

## Датасет

Проект использует набор данных из соревнования на Kaggle: [**Two Sigma Connect: Rental Listing Inquiries**](https://www.kaggle.com/competitions/two-sigma-connect-rental-listing-inquiries/data).

Исходная задача на Kaggle является задачей классификации (предсказание уровня интереса: `low`, `medium`, `high`). Для данного учебного проекта задача была адаптирована под регрессию: категориальная целевая переменная `interest_level` была преобразована в числовую для предсказания с помощью линейных моделей.

## Технологии и библиотеки

*   Python 3.x
*   NumPy
*   Pandas
*   Scikit-learn
*   Jupyter Notebook

## Как запустить

1.  **Клонируйте репозиторий:**
    ```bash
    git clone https://github.com/YOUR_USERNAME/YOUR_REPOSITORY_NAME.git
    cd YOUR_REPOSITORY_NAME
    ```

2.  **Создайте и активируйте виртуальное окружение (рекомендуется):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # для Linux/macOS
    # venv\Scripts\activate    # для Windows
    ```

3.  **Установите зависимости:**
    *Если в репозитории есть файл `requirements.txt`, используйте его. В противном случае установите библиотеки вручную:*
    ```bash
    pip install numpy pandas scikit-learn jupyter
    ```

4.  **Запустите Jupyter Notebook:**
    ```bash
    jupyter notebook
    ```
    В открывшемся окне браузера выберите файл `.ipynb` с решением.

## Теоретические вопросы, рассмотренные в проекте

В ноутбуке даны развернутые ответы на следующие вопросы, демонстрирующие глубину проработки материала:
1.  Вывод аналитического решения для задачи регрессии в векторной форме.
2.  Как изменяется аналитическое решение при добавлении L1 и L2 регуляризации в функцию потерь.
3.  Почему L1 регуляризация (Lasso) часто используется для отбора признаков и обнуляет веса.
4.  Как использовать линейные модели для аппроксимации нелинейных зависимостей (например, с помощью полиномиальных признаков).

